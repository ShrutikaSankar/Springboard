{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax Take Home Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Defining an \"adopted user\" as a user who has logged into the product on three separate days in at least one seven day period, identify which factors predict future user adoption .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two tables one with user engagement and the other table with user characteristics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify adopted users from user engagement table.  Merge list of identified adopted users to user characteristics table. (See code for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "#Load Data\n",
    "\n",
    "#Get Path\n",
    "os.getcwd()\n",
    "basepath = os.getcwd()\n",
    "lis_dir = os.listdir()\n",
    "\n",
    "\n",
    "# Create the list of file names: filenames\n",
    "file = 'takehome_user_engagement.csv'\n",
    "file_name_path = os.path.join(basepath,  file)\n",
    "engagement= pd.read_csv(file_name_path)\n",
    "\n",
    "#Open data\n",
    "engagement.head(5)\n",
    "\n",
    "#time stamp is a date so convert to date time\n",
    "engagement['time_stamp']= pd.to_datetime(engagement['time_stamp'])\n",
    "engagement['time_stamp'] = engagement['time_stamp'].dt.floor('d').astype(np.int64)\n",
    "engagement.pop('visited')\n",
    "\n",
    "#remove duplicates as it does not count as multiple visits if it happens on the same day\n",
    "#sort values by users so we can what how many days per user\n",
    "engagement = engagement.sort_values(['user_id', 'time_stamp']).drop_duplicates() #it doesn't count if it happens 3x in one day\n",
    "\n",
    "\n",
    "#Create window of every three sequential times a user logged in\n",
    "a = engagement.groupby('user_id')['time_stamp'].rolling(window=3)\n",
    "\n",
    "#determine what was the max and min time of for every window call this value b\n",
    "b = pd.to_timedelta((a.max()- a.min())).dt.days\n",
    "\n",
    "#If any value b is less than 7  for a user then the user is an adopted user\n",
    "c = b[b < 8].index.get_level_values('user_id').tolist()\n",
    "\n",
    "#This only needs to happen once\n",
    "c= np.unique(np.array(c)).tolist()\n",
    "print(len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2- Clean user characteristics table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table came with 9 columns and 12000 users. Two of the columns were time variables (creation_time and last_session). There were also null values in the last_session column.   I extracted the month and year from both time stamps, creating four new categories. This allowed us to have the data of which accounts were created when and if that had any value on adopted values. But by doing this we would lose how long the user had been around. So I also created a category called user_time which was the number of days between the userâ€™s last session time from creation time. This also allowed us to get rid of null values since if no last session time was listed I could say the user time was 0 since I would have to assume it was the same as start time. I then could drop both time variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get user data\n",
    "new_file = 'takehome_users.csv'\n",
    "file_name_path2 = os.path.join(basepath, new_file)\n",
    "df = pd.read_csv(file_name_path2,encoding='ISO-8859-1')\n",
    "#if object id is user's id if user id in adopted listed then they are an adopted user\n",
    "df= df.drop_duplicates()\n",
    "df['adopted_user']= df['object_id'].isin(c)\n",
    "\n",
    "#convert dates\n",
    "df['last_session_creation_time']= pd.to_datetime(df['last_session_creation_time'], unit='s')\n",
    "df['creation_time']= pd.to_datetime(df['creation_time'])\n",
    "\n",
    "#extract creation &  last session month and year\n",
    "df['creation_month']= pd.DatetimeIndex(df['creation_time']).month\n",
    "df['creation_year']= pd.DatetimeIndex(df['creation_time']).year\n",
    "df['last_session_month']= pd.DatetimeIndex(df['last_session_creation_time']).month\n",
    "df['last_session_year']= pd.DatetimeIndex(df['last_session_creation_time']).year\n",
    "\n",
    "df['user_time']= (df['last_session_creation_time']-df['creation_time']).dt.days\n",
    "\n",
    "#if no last session creation time we have to assume that the last session was the first (At least with regards to use date)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3- Feature Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the nine original features was email which had over 1100  unique variables. However emails come with three separate parts account name, subdomain and domain. For example for user relax89@yahoo.com : account name (ex:relaxrocks89) ,  subdomain (yahoo) and domain (.com). Subdomains/domains can both divide the data and could tell us a lot about the user (.de domain for example suggests the user is in Germany). There were hundreds of sub domains so I limited it to domains that had over 10 users in for it. This  process was repeated for org_id, and invited user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.nunique())\n",
    "#back of users\n",
    "df['email_loc'] = df['email'].str.split(pat=\"@\").str[-1]\n",
    "df['email_sub_domain'] = df['email_loc'].str.split(pat=\".\").str[0]\n",
    "#df['.de_email'] = np.where(df['email_domain']=='de', True, False)\n",
    "#all domain de is custav sub domain so this was note useful\n",
    "\n",
    "#too many email_locs with values count less than 3 so\n",
    "sub_domain = df.email_sub_domain.value_counts().to_frame()\n",
    "sub_domain= sub_domain[sub_domain>10].dropna()\n",
    "sub_domain_list = sub_domain.index.tolist()\n",
    "df['email_sub_domain'] = np.where(df.email_sub_domain.isin(sub_domain_list), df.email_sub_domain, \"NA\")\n",
    "print(df.nunique())\n",
    "\n",
    "#repeat with org_id\n",
    "#convert to string so later categorical\n",
    "df['org_id'] = df['org_id'].astype(str)\n",
    "\n",
    "#pick top 30 organizations\n",
    "x = df['org_id'].value_counts().to_frame()\n",
    "x= x[x>50].dropna()\n",
    "x_list = x.index.tolist()\n",
    "df['org_id'] = np.where(df.org_id.isin(x_list), df.org_id, \"NA\")\n",
    "\n",
    "\n",
    "#pick top 30 user id\n",
    "x = df['invited_by_user_id'].value_counts().to_frame()\n",
    "x= x[x>10].dropna()\n",
    "x_list = x.index.tolist()\n",
    "df['invited_by_user_id'] = np.where(df.invited_by_user_id.isin(x_list), df.invited_by_user_id, \"NA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4- Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having created these features I split my data into 60% train and 40% test, encoded my categorical features and ran it through a random forest classifier. My random forest came with 85% recall score and .97% accuracy score on the test data. When looking at feature importance user_time turns out to have the highest value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"Confusion Matrix.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5- Visualize Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one variable that is by far the most important- and that is how long they have been using the account. 4 out 5 adopted users have a use date of over 100 days. No adopted user has a zero day value (which makes sense) but over 50% of the non adopted users do. On the flipside a 200 day value has 50% of the adopted users while no non adopted users do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"Feature Importance Violin2.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6- Other Traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less significant traits are email sub domain, creation_source and when the user last played. However these are not as statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"Feature Importance Small.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
